{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SC-1 Feature Engineering and Classification #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first attempt at seriation classification (https://github.com/mmadsen/experiment-seriation-classification/blob/master/analysis/sc-1/sc-1-seriation-classification-analysis.ipynb) was a partial (but encouraging) success, achieving basically 80% accuracy in correctly labeling which of two regional metapopulation models an IDSS seriation solution is derived from.  The \"classifier\" used was simply k-Nearest Neighbors, with an optimal value of k=3.\n",
    "\n",
    "The sole \"feature\" used in classification was the Euclidean distance between sorted Laplacian eigenvalue spectra for each graph, as described in the following lab note:  http://goo.gl/HYvyoM\n",
    "\n",
    "Since I used a single feature in that first analysis, to do better than 80% we're going to have to add more features.  One promising approach is to use more of the information in the Laplacian spectrum itself, instead of reducing it to a single distance metric.  To that, we can then add other graph theoretic features, keeping in mind that some of them may be highly collinear with information already contained in the Laplacian.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cPickle as pickle\n",
    "from copy import deepcopy\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_graphs = pickle.load(open(\"train-freq-graphs.pkl\",'r'))\n",
    "all_labels = pickle.load(open(\"train-freq-labels.pkl\",'r'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The strategy, unlike our first attempt, requires a real train/test split in the dataset because we're going to fit an actual model (although a true LOO cross validation is still of course possible).  But we need a train_test_split function which is able ot deal with lists of NetworkX objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test_split(graph_list, label_list, test_fraction=0.20):\n",
    "    \"\"\"\n",
    "    Randomly splits a set of graphs and labels into training and testing data sets.  We need a custom function\n",
    "    because the dataset isn't a numeric matrix, but a list of NetworkX Graph objects.\n",
    "    \"\"\"\n",
    "    rand_ix = np.random.random_integers(0, len(graph_list), size=int(len(graph_list) * test_fraction))\n",
    "    print \"random indices: %s\" % rand_ix\n",
    "    \n",
    "    test_graphs = []\n",
    "    test_labels = []\n",
    "    \n",
    "    train_graphs = []\n",
    "    train_labels = []\n",
    "    \n",
    "    # first copy the chosen test values, without deleting anything since that would alter the indices\n",
    "    for ix in rand_ix:\n",
    "        test_graphs.append(graph_list[ix])\n",
    "        test_labels.append(label_list[ix])\n",
    "        \n",
    "    # now copy the indices that are NOT in the test index list\n",
    "    for ix in range(0, len(graph_list)):\n",
    "        if ix in rand_ix:\n",
    "            continue\n",
    "        train_graphs.append(graph_list[ix])\n",
    "        train_labels.append(label_list[ix])\n",
    "        \n",
    "    return (train_graphs, train_labels, test_graphs, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal here is to construct a standard training and test data matrix of numeric values, which will contain the sorted Laplacian eigenvalues of the graphs in each data set.  One feature will thus represent the largest eigenvalue for each graph, a second feature will represent the second largest eigenvalue, and so on.  \n",
    "\n",
    "We do not necessarily assume that all of the graphs have the same number of vertices, although if there are marked differences, we would need to handle missing data for those graphs which had many fewer eigenvalues (or restrict our slice of the spectrum to the smallest number of eigenvalues present)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random indices: [66 25 33  6 73 11 53 44 32]\n",
      "train size: 90\n",
      "test size: 9\n"
     ]
    }
   ],
   "source": [
    "train_graphs, train_labels, test_graphs, test_labels = train_test_split(all_graphs, all_labels, test_fraction=0.10)\n",
    "print \"train size: %s\" % len(train_graphs)\n",
    "print \"test size: %s\" % len(test_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def graphs_to_eigenvalue_matrix(graph_list, num_eigenvalues = None):\n",
    "    \"\"\"\n",
    "    Given a list of NetworkX graphs, returns a numeric matrix where rows represent graphs, \n",
    "    and columns represent the reverse sorted eigenvalues of the Laplacian matrix for each graph,\n",
    "    possibly trimmed to only use the num_eigenvalues largest values.  If num_eigenvalues is \n",
    "    unspecified, all eigenvalues are used.\n",
    "    \"\"\"\n",
    "    # peek at the first graph and see how many eigenvalues there are\n",
    "    tg = graph_list[0]\n",
    "    n = len(nx.spectrum.laplacian_spectrum(tg, weight=None))\n",
    "    \n",
    "    # we either use all of the eigenvalues, or we use the smaller of\n",
    "    # the requested number or the actual number (if it is smaller than requested)\n",
    "    if num_eigenvalues is None:\n",
    "        ev_used = n\n",
    "    else:\n",
    "        ev_used = min(n, num_eigenvalues)\n",
    "\n",
    "    print \"(debug) eigenvalues - test graph: %s num_eigenvalues: %s ev_used: %s\" % (n, num_eigenvalues, ev_used)\n",
    "    \n",
    "    data_mat = np.zeros((len(graph_list),ev_used))\n",
    "    #print \"data matrix shape: \", data_mat.shape\n",
    "    \n",
    "    for ix in range(0, len(graph_list)):\n",
    "        spectrum = sorted(nx.spectrum.laplacian_spectrum(graph_list[ix], weight=None), reverse=True)\n",
    "        data_mat[ix,:] = spectrum[0:ev_used]\n",
    "        \n",
    "    return data_mat\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Classifier ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to be using a gradient boosted classifier, which has some of best accuracy of any of the standard classifier methods.  Ultimately we'll figure out the best hyperparameters using cross-validation, but first we just want to see whether the approach gets us anywhere in the right ballpark -- remember, we can 80% accuracy with just eigenvalue distance, so we have to be in that neighborhood or higher to be worth the effort of switching to a more complex model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(debug) eigenvalues - test graph: 30 num_eigenvalues: 20 ev_used: 20\n",
      "(debug) eigenvalues - test graph: 30 num_eigenvalues: 20 ev_used: 20\n"
     ]
    }
   ],
   "source": [
    "train_matrix = graphs_to_eigenvalue_matrix(train_graphs, num_eigenvalues=20)\n",
    "test_matrix = graphs_to_eigenvalue_matrix(test_graphs, num_eigenvalues=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
       "              max_depth=3, max_features=None, max_leaf_nodes=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
       "              random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(n_estimators = 250)\n",
    "clf.fit(train_matrix, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_label = clf.predict(test_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          predicted 0  predicted 1\n",
      "actual 0            6            0\n",
      "actual 1            0            3\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         6\n",
      "          1       1.00      1.00      1.00         3\n",
      "\n",
      "avg / total       1.00      1.00      1.00         9\n",
      "\n",
      "Accuracy on test: 1.000\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(test_labels, pred_label)\n",
    "cmdf = pd.DataFrame(cm)\n",
    "cmdf.columns = map(lambda x: 'predicted {}'.format(x), cmdf.columns)\n",
    "cmdf.index = map(lambda x: 'actual {}'.format(x), cmdf.index)\n",
    "\n",
    "print cmdf\n",
    "print classification_report(test_labels, pred_label)\n",
    "print \"Accuracy on test: %0.3f\" % accuracy_score(test_labels, pred_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definite** improvement over just using the eigenvalue distance, as expected.  Since there's a small data set here, just 90 graphs to train on and 9 in the test set at 10% fraction, the results are somewhat sensitive to the random draw of the test set, but I get values anywhere from 85% to 100% accuracy, with 89% being fairly typical.  \n",
    "\n",
    "I did a run with all 30 eigenvalues and got the same answer as using just the 20 largest eigenvalues, presumably because the smallest 10 are very close to zero and do not vary enough between classes to be useful.  But clearly, tuning this hyperparameter will be useful on the margins.\n",
    "\n",
    "The next step, of course, is to perform a cross validation of the hyperparameters, and write an sklearn-compliant object that makes it easy to cross-validate automatically over the graph objects in various ways, since it would be good to do random splits of the graphs, not just splits of the numeric data matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A second strategy will be to see if augmenting the eigenvalue features with various graph theoretic properties helps at all.  Some features, such as the mean degree of the graph, are likely to be highly redundant, since that information is fully captured by the eigenvalues of the Laplacian matrix (specifically, in its diagonal).  So the trick will be to find some graph metrics which may not be fully captured by the eigenvalues.  That will require more thought, but some of the work I did for the semantic Axelrod paper on graph orbits and symmetries might be useful here.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Optimal Hyperparameters ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "        ('clf', GradientBoostingClassifier())\n",
    "    ])\n",
    "\n",
    "params = {\n",
    "     'clf__learning_rate': [5.0,2.0,1.0, 0.75, 0.5, 0.25, 0.1, 0.05, 0.01],\n",
    "     'clf__n_estimators': [10,25,50,100,250,500]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, params, n_jobs = -1, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 jobs       | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  50 jobs       | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 162 out of 162 | elapsed:    1.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('clf', GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
       "              max_depth=3, max_features=None, max_leaf_nodes=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False))]),\n",
       "       fit_params={}, iid=True, loss_func=None, n_jobs=-1,\n",
       "       param_grid={'clf__learning_rate': [5.0, 2.0, 1.0, 0.75, 0.5, 0.25, 0.1, 0.05, 0.01], 'clf__n_estimators': [10, 25, 50, 100, 250, 500]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, score_func=None, scoring=None,\n",
       "       verbose=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(train_matrix, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.889\n",
      "Best parameters:\n",
      "param: clf__learning_rate: 5.0\n",
      "param: clf__n_estimators: 100\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters:\")\n",
    "best_params = grid_search.best_estimator_.get_params()\n",
    "for param in sorted(params.keys()):\n",
    "    print(\"param: %s: %r\" % (param, best_params[param]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_label = grid_search.predict(test_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          predicted 0  predicted 1\n",
      "actual 0            6            0\n",
      "actual 1            0            3\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         6\n",
      "          1       1.00      1.00      1.00         3\n",
      "\n",
      "avg / total       1.00      1.00      1.00         9\n",
      "\n",
      "Accuracy on test: 1.000\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(test_labels, pred_label)\n",
    "cmdf = pd.DataFrame(cm)\n",
    "cmdf.columns = map(lambda x: 'predicted {}'.format(x), cmdf.columns)\n",
    "cmdf.index = map(lambda x: 'actual {}'.format(x), cmdf.index)\n",
    "\n",
    "print cmdf\n",
    "print classification_report(test_labels, pred_label)\n",
    "print \"Accuracy on test: %0.3f\" % accuracy_score(test_labels, pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
